{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cadf90b-1865-48c4-9082-69c03c33baa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29c38980af0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.manual_seed(1) # set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ab2e565",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import text data\n",
    "with open('datasets/frankenstein.txt', 'r', encoding='utf-8') as file:\n",
    "    frankenstein = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2394afc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter 1\n",
      "\n",
      "_To Mrs. Saville, England._\n",
      "\n",
      "\n",
      "St. Petersburgh, Dec. 11th, 17—.\n",
      "\n",
      "\n",
      "You will rejoice to hear that no disaster has accompanied the\n",
      "commencement of an enterprise which you have regarded with such evil\n",
      "forebodings. I arrived here yesterday, and my first task is to assure\n",
      "my dear sister of my welfare and increasing confidence in the success\n",
      "of my undertaking.\n",
      "\n",
      "I am already far north of London, and as I walk in the streets of\n",
      "Petersburgh, I feel a cold northern breeze play upon my cheeks, which\n",
      "braces my nerves and fills me with delight. Do you understand this\n",
      "feeling? This breeze, which has travelled from the regions towards\n",
      "which I am advancing, gives me a foretaste of those icy climes.\n",
      "Inspirited by this wind of promise, my daydreams become more fervent\n",
      "and vivid. I try in vain to be persuaded that the pole is the seat of\n",
      "frost and desolation; it ever presents itself to my imagination as the\n",
      "region of beauty and delight. There, Margaret, the sun is for ever\n",
      "visible, its broad disk just skirting the horizon and diffusing a\n",
      "perpetual splendour. There—for with your leave, my sister, I will put\n",
      "some trust in preceding navigators—there snow and frost are banished;\n",
      "and, sailing over a calm sea, we may be wafted to a land surpassing in\n",
      "wonders and in beauty every region hitherto discovered on the habitable\n",
      "globe. Its productions and features may be without example, as the\n",
      "phenomena of the heavenly bodies undoubtedly are in those undiscovered\n",
      "solitudes. What may not be expected in a country of eternal light? I\n",
      "may there discover the wondrous power which attracts the needle and may\n",
      "regulate a thousand celestial observations that require only this\n",
      "voyage to render their seeming eccentricities consistent for ever. I\n",
      "shall satiate my ardent curiosity with the sight of a part of the world\n",
      "never before visited, and may tread a land never before imprinted by\n",
      "the foot of man. These are my enticements, and they are sufficient to\n",
      "conquer all fear of danger or death and to induce me to commence this\n",
      "laborious voyage with the joy a child feels when he embarks in a little\n",
      "boat, with his holiday mates, on an expedition of discovery up his\n",
      "native river. But supposing all these conjectures to be false, you\n",
      "cannot contest the inestimable benefit which I shall confer on all\n",
      "mankind, to the last generation, by discovering a passage near the pole\n",
      "to those countries, to reach which at present so many months are\n",
      "requisite; or by ascertaining the secret of the magnet, which, if at\n",
      "all possible, can only be effected by an undertaking such as mine.\n",
      "\n",
      "These reflections have dispelled the agitation with which I began my\n",
      "letter, and I feel my heart glow with an enthusiasm which elevates me\n",
      "to heaven, for nothing contributes so much to tranquillise the mind as\n",
      "a steady purpose—a point on which the soul may fix its intellectual\n",
      "eye. This expedition has been the favourite dream of my early years. I\n",
      "have read with ardour the accounts of the various voyages which have\n",
      "been made in the prospect of arriving at the North Pacific Ocean\n",
      "through the seas which surround the pole. You may remember that a\n",
      "history of all the voyages made for purposes of discovery composed the\n",
      "whole of our good Uncle Thomas’ library. My education was neglected,\n",
      "yet I was passionately fond of reading. These volumes were my study\n",
      "day and night, and my familiarity with them increased that regret which\n",
      "I had felt, as a child, on learning that my father’s dying injunction\n",
      "had forbidden my uncle to allow me to embark in a seafaring life.\n",
      "\n",
      "These visions faded when I perused, for the first time, those poets\n",
      "whose effusions entranced my soul and lifted it to heaven. I also\n",
      "became a poet and for one year lived in a paradise of my own creation;\n",
      "I imagined that I also might obtain a niche in the temple where the\n",
      "names of Homer and Shakespeare are consecrated. You are well\n",
      "acquainted with my failure and how heavily I bore the disappointment.\n",
      "But just at that time I inherited the fortune of my cousin, and my\n",
      "thoughts were turned into the channel of their earlier bent.\n",
      "\n",
      "Six years have passed since I resolved on my present undertaking. I\n",
      "can, even now, remember the hour from which I dedicated myself to this\n",
      "great enterprise. I commenced by inuring my body to hardship. I\n",
      "accompanied the whale-fishers on several expeditions to the North Sea;\n",
      "I voluntarily endured cold, famine, thirst, and want of sleep; I often\n",
      "worked harder than the common sailors during the day and devoted my\n",
      "nights to the study of mathematics, the theory of medicine, and those\n",
      "branches of physical science from which a naval adventurer might derive\n",
      "the greatest practical advantage. Twice I actually hired myself as an\n",
      "under-mate in a Greenland whaler, and acquitted myself to admiration. I\n",
      "must own I felt a little proud when my captain offered me the second\n",
      "dignity in the vessel and entreated me to remain with the greatest\n",
      "earnestness, so valuable did he consider my services.\n",
      "\n",
      "And now, dear Margaret, do I not deserve to accomplish some great purpose?\n",
      "My life might have been passed in ease and luxury, but I preferred glory to\n",
      "every enticement that wealth placed in my path. Oh, that some encouraging\n",
      "voice would answer in the affirmative! My courage and my resolution is\n",
      "firm; but my hopes fluctuate, and my spirits are often depressed. I am\n",
      "about to proceed on a long and difficult voyage, the emergencies of which\n",
      "will demand all my fortitude: I am required not only to raise the spirits\n",
      "of others, but sometimes to sustain my own, when theirs are failing.\n",
      "\n",
      "This is the most favourable period for travelling in Russia. They fly\n",
      "quickly over the snow in their sledges; the motion is pleasant, and, in\n",
      "my opinion, far more agreeable than that of an English stagecoach. The\n",
      "cold is not excessive, if you are wrapped in furs—a dress which I have\n",
      "already adopted, for there is a great difference between walking the\n",
      "deck and remaining seated motionless for hours, when no exercise\n",
      "prevents the blood from actually freezing in your veins. I have no\n",
      "ambition to lose my life on the post-road between St. Petersburgh and\n",
      "Archangel.\n",
      "\n",
      "I shall depart for the latter town in a fortnight or three weeks; and my\n",
      "intention is to hire a ship there, which can easily be done by paying the\n",
      "insurance for the owner, and to engage as many sailors as I think necessary\n",
      "among those who are accustomed to the whale-fishing. I do not intend to\n",
      "sail until the month of June; and when shall I return? Ah, dear sister, how\n",
      "can I answer this question? If I succeed, many, many months, perhaps years,\n",
      "will pass before you and I may meet. If I fail, you will see me again soon,\n",
      "or never.\n",
      "\n",
      "Farewell, my dear, excellent Margaret. Heaven shower down blessings on you,\n",
      "and save me, that I may again and again testify my gratitude for all your\n",
      "love and kindness.\n",
      "\n",
      "Your affectionate brother,\n",
      "\n",
      "R. Walton\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# getting a subset of text so the system wont fail\n",
    "first_letter_text = frankenstein[1380:8230]\n",
    "\n",
    "print(first_letter_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8437daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6850\n"
     ]
    }
   ],
   "source": [
    "# tokenize text\n",
    "tokenized_text = list(first_letter_text)\n",
    "print(len(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c0e03a1-da7a-4c14-b759-3df6a7c13594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping unique tokens\n",
    "unique_char_tokens = sorted(list(set(tokenized_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5dd50f9-27d1-463a-8375-5f25b13b1a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, ',': 3, '-': 4, '.': 5, '1': 6, '7': 7, ':': 8, ';': 9, '?': 10, 'A': 11, 'B': 12, 'D': 13, 'E': 14, 'F': 15, 'G': 16, 'H': 17, 'I': 18, 'J': 19, 'L': 20, 'M': 21, 'N': 22, 'O': 23, 'P': 24, 'R': 25, 'S': 26, 'T': 27, 'U': 28, 'W': 29, 'Y': 30, '_': 31, 'a': 32, 'b': 33, 'c': 34, 'd': 35, 'e': 36, 'f': 37, 'g': 38, 'h': 39, 'i': 40, 'j': 41, 'k': 42, 'l': 43, 'm': 44, 'n': 45, 'o': 46, 'p': 47, 'q': 48, 'r': 49, 's': 50, 't': 51, 'u': 52, 'v': 53, 'w': 54, 'x': 55, 'y': 56, 'z': 57, '—': 58, '’': 59}\n"
     ]
    }
   ],
   "source": [
    "# create a dictionary mapping tokens to unique characters\n",
    "c2ix = {char : idx for idx, char in enumerate(unique_char_tokens)}\n",
    "print(c2ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efabdf2d-82e7-4b6c-957a-7cc3c52165c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse c2ix to be able to match back to characters\n",
    "ix2c = {idx: char for char, idx in c2ix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cb81f5c-6b0e-46f0-8ca3-b2a338bdb7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn our text sample into numerical map\n",
    "tokenized_id_text = [c2ix[char] for char in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "377ed633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "729c2cd4-9d72-4042-9d63-bc8ea5ed58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenized_text, seq_length):\n",
    "        self.tokenized_text = tokenized_text\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_text) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.tensor(self.tokenized_text[idx:idx+self.seq_length])\n",
    "        labels = torch.tensor(self.tokenized_text[idx+1:idx+self.seq_length+1])\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9595e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call textdataset class from previously made to make a dataset of specific size\n",
    "dataset = TextDataset(tokenized_id_text, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68135298",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 36\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "78b77084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin training the neural network\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed240d2b-7aa5-47b3-8bcb-b0c664d6cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CharacterLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim=48)\n",
    "        self.lstm = nn.LSTM(input_size=48, hidden_size=96, batch_first=True)\n",
    "        self.linear = nn.Linear(96, vocab_size)\n",
    "\n",
    "    def forward(self, x, states):\n",
    "        x = self.embedding(x)\n",
    "        output, states = self.lstm(x, states)\n",
    "        output = self.linear(output)\n",
    "        output = output.reshape(-1, output.size(2))\n",
    "        return output, states\n",
    "\n",
    "    def init_state(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, 96)\n",
    "        cell = torch.zeros(1, batch_size, 96)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b79c78f2-3893-40cf-89c2-9884785ed521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of CharacterLSTM() class\n",
    "lstm_model = CharacterLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2b65e394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loss function\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "796ca526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6d73bd69-c0c0-4838-9173-8ac58343eeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tony\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:769: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], CELoss: 1.0969\n",
      "Epoch [2/5], CELoss: 0.7321\n",
      "Epoch [3/5], CELoss: 0.5033\n",
      "Epoch [4/5], CELoss: 0.4037\n",
      "Epoch [5/5], CELoss: 0.4265\n"
     ]
    }
   ],
   "source": [
    "# train model through loop and print loss\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for features, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        states = lstm_model.init_state(features.size(0))\n",
    "        output, states = lstm_model(features, states)\n",
    "        CEloss = loss(output, labels.view(-1,))\n",
    "        CEloss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], CELoss: {CEloss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "946f6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin generating text starting with fixed prompt\n",
    "starting_prompt = \"You will rejoice to hear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "229e64c7-b4f2-488a-9e90-9bed1aec0860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[30, 46, 52,  1, 54, 40, 43, 43,  1, 49, 36, 41, 46, 40, 34, 36,  1, 51,\n",
      "         46,  1, 39, 36, 32, 49]])\n"
     ]
    }
   ],
   "source": [
    "# tokenize starting prompt\n",
    "tokenized_id_prompt = torch.tensor([[c2ix[char] for char in starting_prompt]])\n",
    "\n",
    "print(tokenized_id_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f71c9589-8900-4241-a1c7-716ed744a821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharacterLSTM(\n",
       "  (embedding): Embedding(60, 48)\n",
       "  (lstm): LSTM(48, 96, batch_first=True)\n",
       "  (linear): Linear(in_features=96, out_features=60, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7b8e4357-8cdc-4abf-89fc-08e7354d3618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will rejoice to hear that a\n",
      "history of medicine, and whaler, and when theirs are failing.\n",
      "\n",
      "This is the most favourable period for travelling in Russia. They fly\n",
      "quickly over the secret of the magnet, which, if at\n",
      "all possible, can only be effected by an undertaking such as mine.\n",
      "\n",
      "These reflections and features may be withe months are\n",
      "require only this\n",
      "voyage to render the secret, by ease monts on several expedition has been the favourite dream of my earlier bent.\n",
      "\n",
      "Six years have passed since I resolved on my presen my countrier of my eldicine, and my\n",
      "intention is\n",
      "firm; but my hopes fluctuate, and my first task is to assure\n",
      "my dear sister, I will put\n",
      "some trust in preceding navigators—there snow in their sledges; the motion\n",
      "with which I shall confer on all\n",
      "mankind, to the last generation, by an undertaking such as mine.\n",
      "\n",
      "These reflections and features may be withe months are\n",
      "require only this\n",
      "voyage to render the secret, by ease monts on several expedition has been the favourite dream of my earlier bent.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let the trained model generate text off of prompt.\n",
    "num_generated_chars = 500\n",
    "\n",
    "with torch.no_grad():\n",
    "    states = lstm_model.init_state(1)\n",
    "    for _ in range(num_generated_chars):\n",
    "        output, states = lstm_model(tokenized_id_prompt, states)\n",
    "        predicted_id = torch.argmax(output[-1, :], dim=-1).item()\n",
    "        predicted_char = ix2c[predicted_id]\n",
    "        starting_prompt += predicted_char\n",
    "        tokenized_id_prompt = torch.tensor([[predicted_id]])\n",
    "\n",
    "print(starting_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
